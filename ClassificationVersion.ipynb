{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f571ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "origin_data1 = pd.read_csv('data2/CGM1_dS&dSr.csv', encoding='cp949')\n",
    "origin_data2 = pd.read_csv('data2/CGM2_dS&dSr.csv', encoding='cp949')\n",
    "origin_data3 = pd.read_csv('data2/CGM3_dS&dSr.csv', encoding='cp949')\n",
    "origin_data4 = pd.read_csv('data2/CGM4_dS&dSr.csv', encoding='cp949')\n",
    "origin_data5 = pd.read_csv('data2/CGM5_dS&dSr.csv', encoding='cp949')\n",
    "\n",
    "def filter_data(origin_data, columns):\n",
    "    data = origin_data[columns]\n",
    "    data = data[data[\"Glu(mg/dl)\"] > 0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287790b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1471,  0.1230,  1.2882,  1.9441,  2.2885],\n",
      "        [ 0.5623,  1.4571, -0.6151, -0.3323,  0.9319],\n",
      "        [ 1.3150,  1.7887,  0.4769, -1.0906, -0.4036]], requires_grad=True) tensor([3, 0, 4])\n",
      "tensor([[-0.3337,  0.6885, -0.8246,  0.6627,  0.3959],\n",
      "        [ 1.1728,  1.2563, -1.5232, -2.1289,  1.0615],\n",
      "        [-0.6946, -0.8443, -0.9507,  0.9821,  1.0126]], requires_grad=True) tensor([[0.1339, 0.1282, 0.4066, 0.1993, 0.1320],\n",
      "        [0.0730, 0.1637, 0.4173, 0.1035, 0.2425],\n",
      "        [0.0466, 0.0447, 0.0517, 0.6641, 0.1929]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "inputs = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(inputs, target)\n",
    "output = loss(inputs, target)\n",
    "output.backward()\n",
    "\n",
    "inputs = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(inputs, target)\n",
    "output = loss(inputs, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160b2226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 106 187 342 170 29 6\n"
     ]
    }
   ],
   "source": [
    "common_var = [\"Glu(mg/dl)\", \"LD1 Temp\", \"LD2 Temp\", \"LD3 Temp\", \"Rx1 Temp\", \"Rx2 Temp\", \"S1 T(C)\", \"S2 T(C)\", \"S3 T(C)\", \"FR Mon\", \"LD_Bias_Av\",\n",
    "             \"mPD1_dS\", \"mPD2_dS\", \"mPD3_dS\", \"T-rPD_L1dS\", \"T-rPD_L2dS\", \"T-rPD_L3dS\", \"R-rPD_L1dS\", \"R-rPD_L2dS\", \"R-rPD_L3dS\",\n",
    "             \"mPDdSr31\", \"mPDdSr32\", \"mPDdSr21\", \"T-rPDdSr31\", \"T-rPDdSr32\", \"T-rPDdSr21\", \"R-rPDdSr31\", \"R-rPDdSr32\", \"R-rPDdSr21\"]\n",
    "target_var = [\"Glu(mg/dl)\", \"mPDdSr31\", \"T-rPDdSr31\", \"T-rPDdSr32\", \"R-rPDdSr31\", \"R-rPDdSr21\"]\n",
    "# \"R-rPD_L3dS\", \"mPDdSr31\", \"T-rPDdSr31\", \"T-rPDdSr32\", \"R-rPDdSr31\", \"R-rPDdSr21\"\n",
    "\n",
    "dataR1 = filter_data(origin_data1, target_var)\n",
    "dataR2 = filter_data(origin_data2, target_var)\n",
    "dataR3 = filter_data(origin_data3, target_var)\n",
    "dataR4 = filter_data(origin_data4, target_var)\n",
    "dataR5 = filter_data(origin_data5, target_var)\n",
    "\n",
    "# dataC= pd.concat([dataR1, dataR2, dataR4, dataR5])\n",
    "\n",
    "print(len(dataR1), len(dataR2), len(dataR3), len(dataR4), len(dataR5), len(common_var), len(target_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101f3947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 106 187 342 170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glu(mg/dl)</th>\n",
       "      <th>mPDdSr31</th>\n",
       "      <th>T-rPDdSr31</th>\n",
       "      <th>T-rPDdSr32</th>\n",
       "      <th>R-rPDdSr31</th>\n",
       "      <th>R-rPDdSr21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.022594</td>\n",
       "      <td>0.377709</td>\n",
       "      <td>0.668083</td>\n",
       "      <td>3.295804</td>\n",
       "      <td>2.053209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.023138</td>\n",
       "      <td>0.378598</td>\n",
       "      <td>0.673701</td>\n",
       "      <td>3.320415</td>\n",
       "      <td>2.082137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.015662</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.674252</td>\n",
       "      <td>3.299722</td>\n",
       "      <td>2.075203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.992078</td>\n",
       "      <td>0.374440</td>\n",
       "      <td>0.654474</td>\n",
       "      <td>3.285613</td>\n",
       "      <td>2.090214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.027132</td>\n",
       "      <td>0.372196</td>\n",
       "      <td>0.650426</td>\n",
       "      <td>3.287469</td>\n",
       "      <td>2.089399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.012420</td>\n",
       "      <td>0.319532</td>\n",
       "      <td>0.595589</td>\n",
       "      <td>3.297365</td>\n",
       "      <td>2.059745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.978152</td>\n",
       "      <td>0.325652</td>\n",
       "      <td>0.628451</td>\n",
       "      <td>3.240986</td>\n",
       "      <td>2.022950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.015042</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.605432</td>\n",
       "      <td>3.276478</td>\n",
       "      <td>2.055894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.987656</td>\n",
       "      <td>0.318929</td>\n",
       "      <td>0.599665</td>\n",
       "      <td>3.278780</td>\n",
       "      <td>2.039940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.989797</td>\n",
       "      <td>0.322776</td>\n",
       "      <td>0.610136</td>\n",
       "      <td>3.297117</td>\n",
       "      <td>2.052132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Glu(mg/dl)  mPDdSr31  T-rPDdSr31  T-rPDdSr32  R-rPDdSr31  R-rPDdSr21\n",
       "0           0.0  2.022594    0.377709    0.668083    3.295804    2.053209\n",
       "1           0.0  2.023138    0.378598    0.673701    3.320415    2.082137\n",
       "2           0.0  2.015662    0.377358    0.674252    3.299722    2.075203\n",
       "3           0.0  1.992078    0.374440    0.654474    3.285613    2.090214\n",
       "4           2.0  2.027132    0.372196    0.650426    3.287469    2.089399\n",
       "..          ...       ...         ...         ...         ...         ...\n",
       "290        11.0  2.012420    0.319532    0.595589    3.297365    2.059745\n",
       "291        11.0  1.978152    0.325652    0.628451    3.240986    2.022950\n",
       "292        10.0  2.015042    0.323129    0.605432    3.276478    2.055894\n",
       "293        10.0  1.987656    0.318929    0.599665    3.278780    2.039940\n",
       "294        10.0  1.989797    0.322776    0.610136    3.297117    2.052132\n",
       "\n",
       "[295 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 90~95 : 0, 95~100 : 1, 100~105 : 2, 105~110 : 3, 110~115 : 4, 115~120 : 5, 120~125 : 6, 125~130: 7\n",
    "# 130~135 : 8, 135~140 : 9, 140~145 : 10, 145~150 : 11, 150~155 : 12, 155~160 : 13, 160~ : 14\n",
    "\n",
    "datas = [dataR1, dataR2, dataR3, dataR4, dataR5]\n",
    "sum_data = []\n",
    "\n",
    "for dataR in datas:\n",
    "    data_list = []\n",
    "    for data in dataR.values:\n",
    "        converted = np.array([0])\n",
    "        if data[0] < 95:\n",
    "            converted = np.concatenate((np.array([0]), data[1:]))\n",
    "\n",
    "        elif data[0] < 100 and data[0] >= 95:\n",
    "            converted = np.concatenate((np.array([1]), data[1:]))\n",
    "\n",
    "        elif data[0] < 105 and data[0] >= 100:\n",
    "            converted = np.concatenate((np.array([2]), data[1:]))\n",
    "\n",
    "        elif data[0] < 110 and data[0] >= 105:\n",
    "            converted = np.concatenate((np.array([3]), data[1:]))\n",
    "\n",
    "        elif data[0] < 115 and data[0] >= 110:\n",
    "            converted = np.concatenate((np.array([4]), data[1:]))\n",
    "\n",
    "        elif data[0] < 120 and data[0] >= 115:\n",
    "            converted = np.concatenate((np.array([5]), data[1:]))\n",
    "\n",
    "        elif data[0] < 125 and data[0] >= 120:\n",
    "            converted = np.concatenate((np.array([6]), data[1:]))\n",
    "\n",
    "        elif data[0] < 130 and data[0] >= 125:\n",
    "            converted = np.concatenate((np.array([7]), data[1:]))\n",
    "\n",
    "        elif data[0] < 135 and data[0] >= 130:\n",
    "            converted = np.concatenate((np.array([8]), data[1:]))\n",
    "\n",
    "        elif data[0] < 140 and data[0] >= 135:\n",
    "            converted = np.concatenate((np.array([9]), data[1:]))\n",
    "\n",
    "        elif data[0] < 145 and data[0] >= 140:\n",
    "            converted = np.concatenate((np.array([10]), data[1:]))\n",
    "\n",
    "        elif data[0] < 150 and data[0] >= 145:\n",
    "            converted = np.concatenate((np.array([11]), data[1:]))\n",
    "\n",
    "        elif data[0] < 155 and data[0] >= 150:\n",
    "            converted = np.concatenate((np.array([12]), data[1:]))\n",
    "\n",
    "        elif data[0] < 160 and data[0] >= 155:\n",
    "            converted = np.concatenate((np.array([13]), data[1:]))\n",
    "\n",
    "        elif data[0] >= 160:\n",
    "            converted = np.concatenate((np.array([14]), data[1:]))\n",
    "\n",
    "        data_list.append(converted)\n",
    "    sum_data.append(data_list)\n",
    "\n",
    "data1 = pd.DataFrame(sum_data[0], columns=target_var)\n",
    "data2 = pd.DataFrame(sum_data[1], columns=target_var)\n",
    "data3 = pd.DataFrame(sum_data[2], columns=target_var)\n",
    "data4 = pd.DataFrame(sum_data[3], columns=target_var)\n",
    "data5 = pd.DataFrame(sum_data[4], columns=target_var)\n",
    "print(len(data1), len(data2), len(data3), len(data4), len(data5))\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9268f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def make_yhat(y_data):\n",
    "    y_list = []\n",
    "    for y in y_data:\n",
    "        target = [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "        target[y] = 1.0\n",
    "        y_list.append(target)\n",
    "    print(len(y_list))\n",
    "\n",
    "def preprocess(train_data, test_data) -> tuple:\n",
    "    train_data = train_data.astype({'Glu(mg/dl)':'int'})\n",
    "    test_data = test_data.astype({'Glu(mg/dl)':'int'})\n",
    "    \n",
    "    X_train = train_data.drop('Glu(mg/dl)', axis=1).values\n",
    "    y_train = train_data['Glu(mg/dl)'].values\n",
    "    y_train = y_train.round(0)\n",
    "    \n",
    "    X_test = test_data.drop('Glu(mg/dl)', axis=1).values\n",
    "    y_test = test_data['Glu(mg/dl)'].values\n",
    "    y_test = y_test.round(0)\n",
    "    \n",
    "    sum_data = pd.concat([train_data, test_data])\n",
    "    sum_data = sum_data.drop('Glu(mg/dl)', axis=1).values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(sum_data)\n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return torch.tensor(X_train, dtype=torch.float32), \\\n",
    "        torch.tensor(y_train, dtype=torch.float32), \\\n",
    "        torch.tensor(X_test, dtype=torch.float32), \\\n",
    "        torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# train_data = data1.astype({'Glu(mg/dl)':'int'})\n",
    "# y_train = train_data['Glu(mg/dl)'].values\n",
    "# make_yhat(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfeb5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataC = pd.concat([data1, data4, data5])\n",
    "datas = preprocess(dataC, data2)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(datas[0].unsqueeze(1), datas[1]), batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(datas[2].unsqueeze(1), datas[3]), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b80995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_r2(model, loder, isDT) -> tuple:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    if isDT == False:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in loder:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                y_hat = model(X)\n",
    "                y_pred.append(y_hat.cpu().numpy())\n",
    "                y_true.append(y.cpu().numpy())\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        y_true = np.concatenate(y_true)\n",
    "        r2 = r2_score(y_true, y_pred.squeeze())\n",
    "        return r2\n",
    "    else:\n",
    "        for X, y in loder:\n",
    "            y_hat = model.predict(X.squeeze(0).tolist()) # model(X)\n",
    "            y_hat = torch.Tensor(y_hat)\n",
    "            y_pred.append(y_hat.cpu().numpy())\n",
    "            y_true.append(y.cpu().numpy())\n",
    "\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        y_true = np.concatenate(y_true)\n",
    "        r2 = r2_score(y_true, y_pred.squeeze())\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056f1d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train <class 'str'>: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05660377358490566\n",
      "-0.7046379658271995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_epochs = 10\n",
    "RF = RandomForestClassifier(max_depth=20, n_estimators=100, random_state=0)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=f'Train {str}'):\n",
    "    RF.fit(datas[0], datas[1])\n",
    "\n",
    "print(RF.score(datas[2], datas[3]))\n",
    "r2 = count_r2(RF, test_loader, True)\n",
    "print(r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HnsEnv",
   "language": "python",
   "name": "hnsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
