{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4277067",
   "metadata": {},
   "source": [
    "### 변수 조합별 R2 Score 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb1e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "origin_data1 = pd.read_csv('data2/CGM1_dS&dSr.csv', encoding='cp949')\n",
    "origin_data2 = pd.read_csv('data2/CGM2_dS&dSr.csv', encoding='cp949')\n",
    "origin_data3 = pd.read_csv('data2/CGM3_dS&dSr.csv', encoding='cp949')\n",
    "origin_data4 = pd.read_csv('data2/CGM4_dS&dSr.csv', encoding='cp949')\n",
    "origin_data5 = pd.read_csv('data2/CGM5_dS&dSr.csv', encoding='cp949')\n",
    "\n",
    "def filter_data(origin_data, columns):\n",
    "    data = origin_data[columns]\n",
    "    data = data[data[\"Glu(mg/dl)\"] > 0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3817d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 106 187 342 170\n"
     ]
    }
   ],
   "source": [
    "common_var = [\"Glu(mg/dl)\", \"LD1 Temp\", \"LD2 Temp\", \"LD3 Temp\", \"Rx1 Temp\", \"Rx2 Temp\", \"S1 T(C)\", \"S2 T(C)\", \"S3 T(C)\", \"FR Mon\", \"LD_Bias_Av\",\n",
    "             \"mPD1_dS\", \"mPD2_dS\", \"mPD3_dS\", \"T-rPD_L1dS\", \"T-rPD_L2dS\", \"T-rPD_L3dS\", \"R-rPD_L1dS\", \"R-rPD_L2dS\", \"R-rPD_L3dS\",\n",
    "             \"mPDdSr31\", \"mPDdSr32\", \"mPDdSr21\", \"T-rPDdSr31\", \"T-rPDdSr32\", \"T-rPDdSr21\", \"R-rPDdSr31\", \"R-rPDdSr32\", \"R-rPDdSr21\"]\n",
    "\n",
    "\n",
    "dataR1 = filter_data(origin_data1, common_var)\n",
    "dataR2 = filter_data(origin_data2, common_var)\n",
    "dataR3 = filter_data(origin_data3, common_var)\n",
    "dataR4 = filter_data(origin_data4, common_var)\n",
    "dataR5 = filter_data(origin_data5, common_var)\n",
    "\n",
    "# dataC= pd.concat([dataR1, dataR2, dataR4, dataR5])\n",
    "\n",
    "print(len(dataR1), len(dataR2), len(dataR3), len(dataR4), len(dataR5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9132d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess(train_data, test_data) -> tuple:\n",
    "    train_data = train_data.astype({'Glu(mg/dl)':'int'})\n",
    "    test_data = test_data.astype({'Glu(mg/dl)':'int'})\n",
    "    \n",
    "    X_train = train_data.drop('Glu(mg/dl)', axis=1).values\n",
    "    y_train = train_data['Glu(mg/dl)'].values\n",
    "    y_train = y_train.round(0)\n",
    "    \n",
    "    X_test = test_data.drop('Glu(mg/dl)', axis=1).values\n",
    "    y_test = test_data['Glu(mg/dl)'].values\n",
    "    y_test = y_test.round(0)\n",
    "    \n",
    "    sum_data = pd.concat([train_data, test_data])\n",
    "    sum_data = sum_data.drop('Glu(mg/dl)', axis=1).values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(sum_data)\n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return torch.tensor(X_train, dtype=torch.float32), \\\n",
    "        torch.tensor(y_train, dtype=torch.float32), \\\n",
    "        torch.tensor(X_test, dtype=torch.float32), \\\n",
    "        torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def count_r2(model, loder, isDT) -> tuple:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    if isDT == False:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in loder:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                y_hat = model(X)\n",
    "                y_pred.append(y_hat.cpu().numpy())\n",
    "                y_true.append(y.cpu().numpy())\n",
    "        y_pred = numpy.concatenate(y_pred)\n",
    "        y_true = numpy.concatenate(y_true)\n",
    "        r2 = r2_score(y_true, y_pred.squeeze())\n",
    "        return r2\n",
    "    else:\n",
    "        for X, y in loder:\n",
    "            y_hat = model.predict(X.squeeze(0).tolist()) # model(X)\n",
    "            y_hat = torch.Tensor(y_hat)\n",
    "            y_pred.append(y_hat.cpu().numpy())\n",
    "            y_true.append(y.cpu().numpy())\n",
    "\n",
    "        y_pred = numpy.concatenate(y_pred)\n",
    "        y_true = numpy.concatenate(y_true)\n",
    "        r2 = r2_score(y_true, y_pred.squeeze())\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc40c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import onnx\n",
    "\n",
    "def train_model(model, train_loader, num_epochs, learning_rate, name:str):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model.to(device)\n",
    "    epoch_losses = []\n",
    "    for epoch in tqdm(range(num_epochs), desc=f'Train {name}'):\n",
    "        total_loss = 0\n",
    "        total_batches = 0\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            with torch.set_grad_enabled(True):\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat.squeeze(), y)\n",
    "                total_loss += loss.item()\n",
    "                total_batches += 1\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss = total_loss / total_batches\n",
    "        epoch_losses.append(epoch_loss)\n",
    "    \n",
    "    torch.save(model.state_dict(), f'property2/{name}.pt')\n",
    "    onnx.export(model, X.to(device), f'property2/{name}.onnx')\n",
    "    return epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b29113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train mlp: 100%|███████████████████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.40076979087705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from model import MLP\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "target_var = [\"Glu(mg/dl)\", \"R-rPD_L3dS\", \"mPDdSr31\", \"T-rPDdSr31\", \"T-rPDdSr32\", \"R-rPDdSr31\", \"R-rPDdSr21\"]\n",
    "common_var = [\"Glu(mg/dl)\", \"Rx1 Temp\", \"Rx2 Temp\", \"S1 T(C)\", \"S2 T(C)\", \"S3 T(C)\", \"FR Mon\",\n",
    "             \"mPD1_dS\", \"mPD2_dS\", \"mPD3_dS\", \"T-rPD_L1dS\", \"T-rPD_L2dS\", \"T-rPD_L3dS\", \"R-rPD_L1dS\", \"R-rPD_L2dS\", \"R-rPD_L3dS\",\n",
    "             \"mPDdSr31\", \"mPDdSr32\", \"mPDdSr21\", \"T-rPDdSr31\", \"T-rPDdSr32\", \"T-rPDdSr21\", \"R-rPDdSr31\", \"R-rPDdSr32\", \"R-rPDdSr21\"]\n",
    "# for one_var in common_var:\n",
    "#     train_target = ['Glu(mg/dl)' ,one_var]\n",
    "\n",
    "#     dataR1 = filter_data(origin_data1, train_target)\n",
    "#     dataR2 = filter_data(origin_data2, train_target)\n",
    "#     dataR4 = filter_data(origin_data4, train_target)\n",
    "#     dataR5 = filter_data(origin_data5, train_target)\n",
    "\n",
    "#     dataC= pd.concat([dataR2, dataR4, dataR5])\n",
    "#     datas = preprocess(dataC, dataR1)\n",
    "#     train_loader = DataLoader(TensorDataset(datas[0].unsqueeze(1), datas[1]), batch_size=8, shuffle=True)\n",
    "\n",
    "#     model_mlp = MLP(1)\n",
    "#     losses_mlp = train_model(model_mlp, train_loader, 100, 0.001, 'mlp')\n",
    "\n",
    "#     test_loader = DataLoader(TensorDataset(datas[2].unsqueeze(1), datas[3]), batch_size=1, shuffle=True)\n",
    "#     r2 = count_r2(model_mlp, test_loader, False)\n",
    "\n",
    "#     print(one_var, \" : \", r2)\n",
    "                    \n",
    "dataR1 = filter_data(origin_data1, common_var)\n",
    "dataR2 = filter_data(origin_data2, common_var)\n",
    "dataR4 = filter_data(origin_data4, common_var)\n",
    "dataR5 = filter_data(origin_data5, common_var)\n",
    "dataC= pd.concat([dataR1,dataR4, dataR5])\n",
    "datas = preprocess(dataC, dataR2)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(datas[0].unsqueeze(1), datas[1]), batch_size=8, shuffle=True)\n",
    "\n",
    "model_mlp = MLP(24)\n",
    "losses_mlp = train_model(model_mlp, train_loader, 50, 0.001, 'mlp')\n",
    "\n",
    "test_loader = DataLoader(TensorDataset(datas[2].unsqueeze(1), datas[3]), batch_size=1, shuffle=True)\n",
    "r2 = count_r2(model_mlp, test_loader, False)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14d45c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train <class 'str'>: 100%|█████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-1.5058602991186354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_epochs = 10\n",
    "RF = RandomForestClassifier(max_depth=20, n_estimators=100, random_state=0)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=f'Train {str}'):\n",
    "    RF.fit(datas[0], datas[1])\n",
    "\n",
    "print(RF.score(datas[2], datas[3]))\n",
    "r2 = count_r2(RF, test_loader, True)\n",
    "print(r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HnsEnv",
   "language": "python",
   "name": "hnsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
