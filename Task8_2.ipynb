{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e2e7ba1",
   "metadata": {},
   "source": [
    "### 실제 데이터 테스트2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4192a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_data(file_path, columns):\n",
    "    origin_data= pd.read_csv('data2/CGM1_dSL1.csv', encoding='cp949')\n",
    "\n",
    "origin_data1_1 = pd.read_csv('data2/CGM1_dSL1.csv', encoding='cp949')\n",
    "origin_data1_2 = pd.read_csv('data2/CGM1_dSL2.csv', encoding='cp949')\n",
    "origin_data1_3 = pd.read_csv('data2/CGM1_dSL3.csv', encoding='cp949')\n",
    "origin_data1_21 = pd.read_csv('data2/CGM1_dSr21.csv', encoding='cp949')\n",
    "origin_data1_31 = pd.read_csv('data2/CGM1_dSr31.csv', encoding='cp949')\n",
    "origin_data1_32 = pd.read_csv('data2/CGM1_dSr32.csv', encoding='cp949')\n",
    "\n",
    "origin_data2_1 = pd.read_csv('data2/CGM2_dSL1.csv', encoding='cp949')\n",
    "origin_data2_2 = pd.read_csv('data2/CGM2_dSL2.csv', encoding='cp949')\n",
    "origin_data2_3 = pd.read_csv('data2/CGM2_dSL3.csv', encoding='cp949')\n",
    "origin_data2_21 = pd.read_csv('data2/CGM2_dSr21.csv', encoding='cp949')\n",
    "origin_data2_31 = pd.read_csv('data2/CGM2_dSr31.csv', encoding='cp949')\n",
    "origin_data2_32 = pd.read_csv('data2/CGM2_dSr32.csv', encoding='cp949')\n",
    "\n",
    "origin_data3_1 = pd.read_csv('data2/CGM3_dSL1.csv', encoding='cp949')\n",
    "origin_data3_2 = pd.read_csv('data2/CGM3_dSL2.csv', encoding='cp949')\n",
    "origin_data3_3 = pd.read_csv('data2/CGM3_dSL3.csv', encoding='cp949')\n",
    "origin_data3_21 = pd.read_csv('data2/CGM3_dSr21.csv', encoding='cp949')\n",
    "origin_data3_31 = pd.read_csv('data2/CGM3_dSr31.csv', encoding='cp949')\n",
    "origin_data3_32 = pd.read_csv('data2/CGM3_dSr32.csv', encoding='cp949')\n",
    "\n",
    "origin_data4_1 = pd.read_csv('data2/CGM4_dSL1.csv', encoding='cp949')\n",
    "origin_data4_2 = pd.read_csv('data2/CGM4_dSL2.csv', encoding='cp949')\n",
    "origin_data4_3 = pd.read_csv('data2/CGM4_dSL3.csv', encoding='cp949')\n",
    "origin_data4_21 = pd.read_csv('data2/CGM4_dSr21.csv', encoding='cp949')\n",
    "origin_data4_31 = pd.read_csv('data2/CGM4_dSr31.csv', encoding='cp949')\n",
    "origin_data4_32 = pd.read_csv('data2/CGM4_dSr32.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89838c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 106 187 343\n",
      "744 744 744 744 744 744\n"
     ]
    }
   ],
   "source": [
    "def filter_data(origin_data, columns):\n",
    "    data = origin_data[columns]\n",
    "    data = data[data[\"Glu2(mg/dl)\"] > 0]\n",
    "    data = data[data[columns[3]] != 0]\n",
    "    return data\n",
    "\n",
    "common_var = [\"Glu2(mg/dl)\", \"LD1 Temp\", \"LD2 Temp\", \"LD3 Temp\", \"Rx1 Temp\", \"Rx2 Temp\", \"S1 T(C)\", \"S2 T(C)\", \"S3 T(C)\", \"FR Mon\", \"LD_Bias_Av\"]\n",
    "columns1 = common_var + [\"mPD1_dS\", \"T-rPD_L1dS\", \"R-rPD_L1dS\"]\n",
    "columns2 = common_var + [\"mPD2_dS\", \"T-rPD_L2dS\", \"R-rPD_L2dS\"]\n",
    "columns3 = common_var + [\"mPD3_dS\", \"T-rPD_L3dS\", \"R-rPD_L3dS\"]\n",
    "columns21 = common_var + [\"mPDdSr21\", \"T-rPDdSr21\", \"R-rPDdSr21\"]\n",
    "columns31 = common_var + [\"mPDdSr31\", \"T-rPDdSr31\", \"R-rPDdSr31\"]\n",
    "columns32 = common_var + [\"mPDdSr32\", \"T-rPDdSr32\", \"R-rPDdSr32\"]\n",
    "\n",
    "data_R1_1 = filter_data(origin_data1_1, columns1)\n",
    "data_R1_2 = filter_data(origin_data1_2, columns2)\n",
    "data_R1_3 = filter_data(origin_data1_3, columns3)\n",
    "data_R1_21 = filter_data(origin_data1_21, columns21)\n",
    "data_R1_31 = filter_data(origin_data1_31, columns31)\n",
    "data_R1_32 = filter_data(origin_data1_32, columns32)\n",
    "\n",
    "data_R2_1 = filter_data(origin_data2_1, columns1)\n",
    "data_R2_2 = filter_data(origin_data2_2, columns2)\n",
    "data_R2_3 = filter_data(origin_data2_3, columns3)\n",
    "data_R2_21 = filter_data(origin_data2_21, columns21)\n",
    "data_R2_31 = filter_data(origin_data2_31, columns31)\n",
    "data_R2_32 = filter_data(origin_data2_32, columns32)\n",
    "\n",
    "data_R3_1 = filter_data(origin_data3_1, columns1)\n",
    "data_R3_2 = filter_data(origin_data3_2, columns2)\n",
    "data_R3_3 = filter_data(origin_data3_3, columns3)\n",
    "data_R3_21 = filter_data(origin_data3_21, columns21)\n",
    "data_R3_31 = filter_data(origin_data3_31, columns31)\n",
    "data_R3_32 = filter_data(origin_data3_32, columns32)\n",
    "\n",
    "data_R4_1 = filter_data(origin_data4_1, columns1)\n",
    "data_R4_2 = filter_data(origin_data4_2, columns2)\n",
    "data_R4_3 = filter_data(origin_data4_3, columns3)\n",
    "data_R4_21 = filter_data(origin_data4_21, columns21)\n",
    "data_R4_31 = filter_data(origin_data4_31, columns31)\n",
    "data_R4_32 = filter_data(origin_data4_32, columns32)\n",
    "\n",
    "\n",
    "# cgm3는 제외\n",
    "data1 = pd.concat([data_R1_1, data_R2_1, data_R4_1])\n",
    "data2 = pd.concat([data_R1_2, data_R2_2, data_R4_2])\n",
    "data3 = pd.concat([data_R1_3, data_R2_3, data_R4_3])\n",
    "data21 = pd.concat([data_R1_21, data_R2_21, data_R4_21])\n",
    "data31 = pd.concat([data_R1_31, data_R2_31, data_R4_31])\n",
    "data32 = pd.concat([data_R1_32, data_R2_32, data_R4_32])\n",
    "\n",
    "print(len(data_R1_1), len(data_R2_1), len(data_R3_1), len(data_R4_1))\n",
    "print(len(data1), len(data2), len(data3), len(data21), len(data31), len(data32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d5fc5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess(data , dt=False) -> tuple:\n",
    "    if dt:\n",
    "        # data = data\n",
    "        data = data.round(0).astype({'Glu2(mg/dl)':'int'})\n",
    "    \n",
    "    X = data.drop('Glu2(mg/dl)', axis=1).values\n",
    "    y = data['Glu2(mg/dl)'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return torch.tensor(X_train, dtype=torch.float32), \\\n",
    "        torch.tensor(y_train, dtype=torch.float32), \\\n",
    "        torch.tensor(X_test, dtype=torch.float32), \\\n",
    "        torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "data1 = preprocess(data1, True)\n",
    "data2 = preprocess(data2, True)\n",
    "data3 = preprocess(data3, True)\n",
    "data21 = preprocess(data21, True)\n",
    "data31 = preprocess(data31, True)\n",
    "data32 = preprocess(data32, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d49bb0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([130., 144.,  95., 141.,  95.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data31[1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98387ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import onnx\n",
    "\n",
    "def train_model(model, train_loader, num_epochs, learning_rate, name:str):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model.to(device)\n",
    "    epoch_losses = []\n",
    "    for epoch in tqdm(range(num_epochs), desc=f'Train {name}'):\n",
    "        total_loss = 0\n",
    "        total_batches = 0\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            with torch.set_grad_enabled(True):\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat.squeeze(), y)\n",
    "                total_loss += loss.item()\n",
    "                total_batches += 1\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss = total_loss / total_batches\n",
    "        epoch_losses.append(epoch_loss)\n",
    "    \n",
    "    torch.save(model.state_dict(), f'property2/{name}.pt')\n",
    "    onnx.export(model, X.to(device), f'property2/{name}.onnx')\n",
    "    return epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_loader1 = DataLoader(TensorDataset(data1[0].unsqueeze(1), data1[1]), batch_size=batch_size, shuffle=True)\n",
    "train_loader2 = DataLoader(TensorDataset(data2[0].unsqueeze(1), data2[1]), batch_size=batch_size, shuffle=True)\n",
    "train_loader3 = DataLoader(TensorDataset(data3[0].unsqueeze(1), data3[1]), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loader21 = DataLoader(TensorDataset(data21[0].unsqueeze(1), data21[1]), batch_size=batch_size, shuffle=True)\n",
    "train_loader31 = DataLoader(TensorDataset(data31[0].unsqueeze(1), data31[1]), batch_size=batch_size, shuffle=True)\n",
    "train_loader32 = DataLoader(TensorDataset(data32[0].unsqueeze(1), data32[1]), batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MLP, Conv1DModel, LinearRegressionModel\n",
    "\n",
    "model_conv1d1 = Conv1DModel(1, 2)\n",
    "model_conv1d2 = Conv1DModel(1, 2)\n",
    "model_conv1d3 = Conv1DModel(1, 2)\n",
    "model_conv1d21 = Conv1DModel(1, 2)\n",
    "model_conv1d31 = Conv1DModel(1, 2)\n",
    "model_conv1d32 = Conv1DModel(1, 2)\n",
    "\n",
    "losses_conv1d1 = train_model(model_conv1d1, train_loader1, num_epochs, learning_rate, 'conv1d1')\n",
    "losses_conv1d2 = train_model(model_conv1d2, train_loader2, num_epochs, learning_rate, 'conv1d2')\n",
    "losses_conv1d3 = train_model(model_conv1d3, train_loader3, num_epochs, learning_rate, 'conv1d3')\n",
    "losses_conv1d21 = train_model(model_conv1d21, train_loader21, num_epochs, learning_rate, 'conv1d21')\n",
    "losses_conv1d31 = train_model(model_conv1d31, train_loader31, num_epochs, learning_rate, 'conv1d31')\n",
    "losses_conv1d32 = train_model(model_conv1d32, train_loader32, num_epochs, learning_rate, 'conv1d32')\n",
    "\n",
    "\n",
    "model_mlp1 = MLP(13)\n",
    "model_mlp2 = MLP(13)\n",
    "model_mlp3 = MLP(13)\n",
    "model_mlp21 = MLP(13)\n",
    "model_mlp31 = MLP(13)\n",
    "model_mlp32 = MLP(13)\n",
    "\n",
    "losses_mlp1 = train_model(model_mlp1, train_loader1, num_epochs, learning_rate, 'mlp1')\n",
    "losses_mlp2 = train_model(model_mlp2, train_loader2, num_epochs, learning_rate, 'mlp2')\n",
    "losses_mlp3 = train_model(model_mlp3, train_loader3, num_epochs, learning_rate, 'mlp3')\n",
    "losses_mlp21 = train_model(model_mlp21, train_loader21, num_epochs, learning_rate, 'mlp21')\n",
    "losses_mlp31 = train_model(model_mlp31, train_loader31, num_epochs, learning_rate, 'mlp31')\n",
    "losses_mlp32 = train_model(model_mlp32, train_loader32, num_epochs, learning_rate, 'mlp32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0416baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def draw_graph(ax, loss_mlp, loss_conv1d, title):\n",
    "    ax.plot(loss_mlp, label='MLP')\n",
    "    ax.plot(loss_conv1d, label='Conv1D')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(0, 500)\n",
    "    ax.set_xlim(0, num_epochs)\n",
    "\n",
    "    \n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('Set1')\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 2, figsize=(20, 15))\n",
    "draw_graph(ax1[0], losses_mlp1, losses_conv1d1, 'R1')\n",
    "draw_graph(ax1[1], losses_mlp21, losses_conv1d21, 'R21')\n",
    "draw_graph(ax2[0], losses_mlp2, losses_conv1d2, 'R2')\n",
    "draw_graph(ax2[1], losses_mlp31, losses_conv1d31, 'R31')\n",
    "draw_graph(ax3[0], losses_mlp3, losses_conv1d3, 'R3')\n",
    "draw_graph(ax3[1], losses_mlp32, losses_conv1d32, 'R32')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def model_infer(model, loder) -> tuple:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in loder:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = model(X)\n",
    "            y_pred.append(y_hat.cpu().numpy())\n",
    "            y_true.append(y.cpu().numpy())\n",
    "    y_pred = numpy.concatenate(y_pred)\n",
    "    y_true = numpy.concatenate(y_true)\n",
    "    rms = numpy.sqrt(mean_squared_error(y_true, y_pred.squeeze()))\n",
    "    r2 = r2_score(y_true, y_pred.squeeze())\n",
    "    return y_pred, y_true, rms, r2  \n",
    "\n",
    "def append_graph(ax, y, y_pred, title):\n",
    "    ax.scatter(y, y_pred, s=1, label=title)# 'MLP_L23'\n",
    "    ax.plot([75, 200], [75, 200], 'k--')\n",
    "    ax.set_xlabel('True')\n",
    "    ax.set_ylabel('Pred')\n",
    "    ax.set_title(f'{title} (RMS: {rms:.2f}, R2: {r2:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a446eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader1 = DataLoader(TensorDataset(data1[2].unsqueeze(1), data1[3]), batch_size=1, shuffle=True)\n",
    "test_loader2 = DataLoader(TensorDataset(data2[2].unsqueeze(1), data2[3]), batch_size=1, shuffle=True)\n",
    "test_loader3 = DataLoader(TensorDataset(data3[2].unsqueeze(1), data3[3]), batch_size=1, shuffle=True)\n",
    "test_loader21 = DataLoader(TensorDataset(data21[2].unsqueeze(1), data21[3]), batch_size=1, shuffle=True)\n",
    "test_loader31 = DataLoader(TensorDataset(data31[2].unsqueeze(1), data31[3]), batch_size=1, shuffle=True)\n",
    "test_loader32 = DataLoader(TensorDataset(data32[2].unsqueeze(1), data32[3]), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51288350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('Set1')\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax21, ax31, ax32) = plt.subplots(6, 2, figsize=(20, 20))\n",
    "\n",
    "y_pred, y_true, rms, r2 = model_infer(model_mlp1, test_loader1)\n",
    "append_graph(ax1[0], y_true, y_pred, 'MLP1')\n",
    "y_pred, y_true, rms, r2 = model_infer(model_conv1d1, test_loader1)\n",
    "append_graph(ax1[1], y_true, y_pred, 'Conv1d1')\n",
    "\n",
    "\n",
    "y_pred, y_true, rms, r2 = model_infer(model_mlp2, test_loader2)\n",
    "append_graph(ax2[0], y_true, y_pred, 'MLP2')\n",
    "y_pred, y_true, rms, r2 = model_infer(model_conv1d2, test_loader2)\n",
    "append_graph(ax2[1], y_true, y_pred, 'Conv1d2')\n",
    "\n",
    "\n",
    "y_pred, y_true, rms, r2 = model_infer(model_mlp3, test_loader3)\n",
    "append_graph(ax3[0], y_true, y_pred, 'MLP3')\n",
    "y_pred, y_true, rms, r2 = model_infer(model_conv1d3, test_loader3)\n",
    "append_graph(ax3[1], y_true, y_pred, 'Conv1d3')\n",
    "\n",
    "y_pred, y_true, rms, r2 = model_infer(model_mlp21, test_loader21)\n",
    "append_graph(ax21[0], y_true, y_pred, 'MLP21')\n",
    "y_pred, y_true, rms, r2 = model_infer(model_conv1d21, test_loader21)\n",
    "append_graph(ax21[1], y_true, y_pred, 'Conv1d21')\n",
    "\n",
    "y_pred, y_true, rms, r2 = model_infer(model_mlp31, test_loader31)\n",
    "append_graph(ax31[0], y_true, y_pred, 'MLP31')\n",
    "y_pred, y_true, rms, r2 = model_infer(model_conv1d31, test_loader31)\n",
    "append_graph(ax31[1], y_true, y_pred, 'Conv1d31')\n",
    "\n",
    "y_pred, y_true, rms, r2 = model_infer(model_mlp32, test_loader32)\n",
    "append_graph(ax32[0], y_true, y_pred, 'MLP32')\n",
    "y_pred, y_true, rms, r2 = model_infer(model_conv1d32, test_loader32)\n",
    "append_graph(ax32[1], y_true, y_pred, 'Conv1d32')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "RF1 = RandomForestClassifier(max_depth=20, n_estimators=100, random_state=0)\n",
    "RF2 = RandomForestClassifier(max_depth=20, n_estimators=100, random_state=0)\n",
    "RF3 = RandomForestClassifier(max_depth=20, n_estimators=100, random_state=0)\n",
    "RF21 = RandomForestClassifier(max_depth=20, n_estimators=100, random_state=0)\n",
    "RF31 = RandomForestClassifier(max_depth=20, n_estimators=100, random_state=0)\n",
    "RF32 = RandomForestClassifier(max_depth=20, n_estimators=100, random_state=0)\n",
    "\n",
    "GB1 = GradientBoostingClassifier(max_depth=10, n_estimators=100, random_state=0)\n",
    "GB2 = GradientBoostingClassifier(max_depth=10, n_estimators=100, random_state=0)\n",
    "GB3 = GradientBoostingClassifier(max_depth=10, n_estimators=100, random_state=0)\n",
    "GB21 = GradientBoostingClassifier(max_depth=10, n_estimators=100, random_state=0)\n",
    "GB31 = GradientBoostingClassifier(max_depth=10, n_estimators=100, random_state=0)\n",
    "GB32 = GradientBoostingClassifier(max_depth=10, n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=f'Train {str}'):\n",
    "    RF1.fit(data1[0], data1[1])\n",
    "    RF2.fit(data2[0], data2[1])\n",
    "    RF3.fit(data3[0], data3[1])\n",
    "    RF21.fit(data21[0], data21[1])\n",
    "    RF31.fit(data31[0], data31[1])\n",
    "    RF32.fit(data32[0], data32[1])\n",
    "    \n",
    "    GB1.fit(data1[0], data1[1])\n",
    "    GB2.fit(data2[0], data2[1])\n",
    "    GB3.fit(data3[0], data3[1])\n",
    "    GB21.fit(data21[0], data21[1])\n",
    "    GB31.fit(data31[0], data31[1])\n",
    "    GB32.fit(data32[0], data32[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1272bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RF1.score(data1[2], data1[3]))\n",
    "print(RF2.score(data2[2], data2[3]))\n",
    "print(RF3.score(data3[2], data3[3]))\n",
    "print(RF21.score(data21[2], data21[3]))\n",
    "print(RF31.score(data31[2], data31[3]))\n",
    "print(RF32.score(data32[2], data32[3]))\n",
    "\n",
    "print(GB1.score(data1[2], data1[3]))\n",
    "print(GB2.score(data2[2], data2[3]))\n",
    "print(GB3.score(data3[2], data3[3]))\n",
    "print(GB21.score(data21[2], data21[3]))\n",
    "print(GB31.score(data31[2], data31[3]))\n",
    "print(GB32.score(data32[2], data32[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a0505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_result_sample(data, model, count):\n",
    "    y_h = []; pred = []\n",
    "    for i in range(0, count):\n",
    "        y_h.append(data[3][i])\n",
    "        \n",
    "        result = model.predict([data[2][i].tolist()])\n",
    "        pred.append(result)\n",
    "    \n",
    "    return y_h, pred\n",
    "\n",
    "statistic_RF = pd.DataFrame(columns=[\"RF1_y\",\"RF1_pred\",\"RF2_y\",\"RF2_pred\",\"RF3_y\",\"RF3_pred\",\n",
    "                                        \"RF21_y\",\"RF21_pred\",\"RF31_y\",\"RF31_pred\",\"RF32_y\",\"RF32_pred\"])\n",
    "statistic_GB = pd.DataFrame(columns=[\"GB1_y\",\"GB1_pred\",\"GB2_y\",\"GB2_pred\",\"GB3_y\",\"GB3_pred\",\n",
    "                                        \"GB21_y\",\"GB21_pred\",\"GB31_y\",\"GB31_pred\",\"GB32_y\",\"GB32_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_RF[\"RF1_y\"], statistic_RF[\"RF1_pred\"] = make_result_sample(data1, RF1, 5)\n",
    "statistic_RF[\"RF2_y\"], statistic_RF[\"RF2_pred\"] = make_result_sample(data2, RF2, 5)\n",
    "statistic_RF[\"RF3_y\"], statistic_RF[\"RF3_pred\"] = make_result_sample(data3, RF3, 5)\n",
    "statistic_RF[\"RF21_y\"], statistic_RF[\"RF21_pred\"] = make_result_sample(data21, RF21, 5)\n",
    "statistic_RF[\"RF31_y\"], statistic_RF[\"RF31_pred\"] = make_result_sample(data31, RF31, 5)\n",
    "statistic_RF[\"RF32_y\"], statistic_RF[\"RF32_pred\"] = make_result_sample(data32, RF32, 5)\n",
    "\n",
    "statistic_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_GB[\"GB1_y\"], statistic_GB[\"GB1_pred\"] = make_result_sample(data1, GB1, 5)\n",
    "statistic_GB[\"GB2_y\"], statistic_GB[\"GB2_pred\"] = make_result_sample(data2, GB2, 5)\n",
    "statistic_GB[\"GB3_y\"], statistic_GB[\"GB3_pred\"] = make_result_sample(data3, GB3, 5)\n",
    "statistic_GB[\"GB21_y\"], statistic_GB[\"GB21_pred\"] = make_result_sample(data21, GB21, 5)\n",
    "statistic_GB[\"GB31_y\"], statistic_GB[\"GB31_pred\"] = make_result_sample(data31, GB31, 5)\n",
    "statistic_GB[\"GB32_y\"], statistic_GB[\"GB32_pred\"] = make_result_sample(data32, GB32, 5)\n",
    "\n",
    "statistic_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93880f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_infer(model, loder) -> tuple:\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for X, y in loder:\n",
    "        y_hat = model.predict(X.squeeze(0).tolist()) # model(X)\n",
    "        y_hat = torch.Tensor(y_hat)\n",
    "        y_pred.append(y_hat.cpu().numpy())\n",
    "        y_true.append(y.cpu().numpy())\n",
    "        \n",
    "    y_pred = numpy.concatenate(y_pred)\n",
    "    y_true = numpy.concatenate(y_true)\n",
    "    rms = numpy.sqrt(mean_squared_error(y_true, y_pred.squeeze()))\n",
    "    r2 = r2_score(y_true, y_pred.squeeze())\n",
    "    return y_pred, y_true, rms, r2\n",
    "\n",
    "def draw_DTgraph(ax, model, loader, title):\n",
    "    y_pred, y_true, rms, r2 = model_infer(model, loader)\n",
    "    ax.scatter(y_true, y_pred, s=1, label=title)\n",
    "    ax.plot([75, 200], [75, 200], 'k--')\n",
    "    ax.set_xlabel('True')\n",
    "    ax.set_ylabel('Pred')\n",
    "    ax.set_title(f'{title} (RMS: {rms:.2f}, R2: {r2:.2f})') # f'R31 RandomForest (RMS: {rms:.2f}, R2: {r2:.2f})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1574775",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax21, ax31, ax32) = plt.subplots(6, 2, figsize=(20, 20))\n",
    "draw_DTgraph(ax1[0], RF1, test_loader1, 'RF1')\n",
    "draw_DTgraph(ax1[1], GB1, test_loader1, 'GB1')\n",
    "draw_DTgraph(ax2[0], RF2, test_loader2, 'RF2')\n",
    "draw_DTgraph(ax2[1], GB2, test_loader2, 'GB2')\n",
    "draw_DTgraph(ax3[0], RF3, test_loader3, 'RF3')\n",
    "draw_DTgraph(ax3[1], GB3, test_loader3, 'GB3')\n",
    "\n",
    "draw_DTgraph(ax21[0], RF21, test_loader21, 'RF21')\n",
    "draw_DTgraph(ax21[1], GB21, test_loader21, 'GB21')\n",
    "draw_DTgraph(ax31[0], RF31, test_loader31, 'RF31')\n",
    "draw_DTgraph(ax31[1], GB31, test_loader31, 'GB31')\n",
    "draw_DTgraph(ax32[0], RF32, test_loader32, 'RF32')\n",
    "draw_DTgraph(ax32[1], GB32, test_loader32, 'GB32')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bfa4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(RF1, \"property2/rf1_test.joblib\")\n",
    "joblib.dump(RF2, \"property2/rf2_test.joblib\")\n",
    "joblib.dump(RF3, \"property2/rf3_test.joblib\")\n",
    "joblib.dump(RF31, \"property2/rf31_test.joblib\")\n",
    "joblib.dump(RF21, \"property2/rf21_test.joblib\")\n",
    "joblib.dump(RF32, \"property2/rf32_test.joblib\")\n",
    "\n",
    "joblib.dump(GB1, \"property2/gb1_test.joblib\")\n",
    "joblib.dump(GB2, \"property2/gb2_test.joblib\")\n",
    "joblib.dump(GB3, \"property2/gb3_test.joblib\")\n",
    "joblib.dump(GB31, \"property2/gb31_test.joblib\")\n",
    "joblib.dump(GB21, \"property2/gb21_test.joblib\")\n",
    "joblib.dump(GB32, \"property2/gb32_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371237ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF31 = joblib.load(\"property2/rf31_test.joblib\")\n",
    "model_RF2 = joblib.load(\"property2/rf2_test.joblib\")\n",
    "model_GB = joblib.load(\"property2/gb31_test.joblib\")\n",
    "\n",
    "print(model_RF2.predict(data2[2][0:20]))\n",
    "print(data2[3][0:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HnsEnv",
   "language": "python",
   "name": "hnsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
